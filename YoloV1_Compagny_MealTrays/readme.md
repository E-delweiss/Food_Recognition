# Introduction
This notebook aims to help the reader to walk through the YoloV1 code for Food Recognition on company meal trays. It will not explain the whole code here but will focus on the most important parts.

The first project of this repo *[WarmingUp_with_MNIST](https://github.com/E-delweiss/Food_Recognition/tree/main/WarmingUp_with_MNIST)* helps to understand the Yolo mindset with a unique object localization (MNIST digit). 

Some helpfull links :
* YoloV1 [paper](https://arxiv.org/pdf/1506.02640.pdf)
* GitHub [repo](https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/object_detection) of @aladdinpersson
* GitHup [repo](https://github.com/pjreddie/darknet) of @pjreddie
* Excellent [web page](https://pjreddie.com/darknet/yolo/) about Yolo, Darknet models, and other stuffs from @Joseph Chet Redmon


### Terminology :
* B : number of bounding boxes generated by the model (here 2)
* C : number of classes (here 8)
* S : number of grid cells in one direction (here 7)
* \*r or \*r_img : indicate a value *relatives to the image size*
* \*cr_img : indicate a **center** value *relatives to the image size*
* \*r_cell : indicate a value *relatives to a cell*
* \*cr_cell : indicate a **center** value *relatives to a cell*

# Dataset
I used my own [meal trays dataset](https://github.com/E-delweiss/mealtray_dataset) which consists of 3278 images of company meal trays. Only 480 have been labellised by myself. I believed it was a enough to produce a proof of concept. Each meal tray contains `n` objects among 8 categories :
* Plate (the main dish)
* Starter
* Bread
* Drink
* Yogurt
* Desert
* Fruit
* Cheese


[In process...]
###############################################
