{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_MNIST_Localization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjcoYKqIxMcQWMv/vjV4jd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThOpaque/Food_Recognition/blob/main/YOLO_MNIST_Localization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAHeh1BRufX4"
      },
      "outputs": [],
      "source": [
        "import os, time,datetime\n",
        "from timeit import default_timer as timer\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "!pip install torchinfo;\n",
        "!pip install torchmetrics;\n",
        "from torchmetrics import MeanSquaredError;\n",
        "from torchinfo import summary;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im_width = 75\n",
        "im_height = 75\n",
        "use_normalized_coordinates = True\n",
        "\n",
        "def draw_ONE_bounding_box_on_image(image, ymin:int, xmin:int, ymax:int, xmax:int, \n",
        "                               color:str='red', thickness:int=1, display_str:bool=None, \n",
        "                               use_normalized_coordinates:bool=True):\n",
        "  \"\"\"Adds a bounding box to an image.\n",
        "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
        "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
        "  \n",
        "  Args:\n",
        "    image: a PIL.Image object.\n",
        "    ymin: ymin of bounding box.\n",
        "    xmin: xmin of bounding box.\n",
        "    ymax: ymax of bounding box.\n",
        "    xmax: xmax of bounding box.\n",
        "    color: color to draw bounding box. Default is red.\n",
        "    thickness: line thickness. Default value is 4.\n",
        "    display_str_list: string to display in box\n",
        "    use_normalized_coordinates: If True (default), treat coordinates\n",
        "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
        "      coordinates as absolute.\n",
        "  \"\"\"\n",
        "  draw = PIL.ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  \n",
        "  if use_normalized_coordinates:\n",
        "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                  ymin * im_height, ymax * im_height)\n",
        "  else:\n",
        "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom),\n",
        "             (right, top), (left, top)], width=thickness, fill=color)\n",
        "\n",
        "\n",
        "\n",
        "def draw_bounding_boxes_on_image(image, boxes:np.ndarray, color:list=[], \n",
        "                                 thickness:int=1, display_str_list:tuple=()):\n",
        "  \"\"\"Draws bounding boxes on image.\n",
        "\n",
        "  Args:\n",
        "    image: a PIL.Image object.\n",
        "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
        "           The coordinates are in normalized format between [0, 1].\n",
        "    color: color to draw bounding box. Default is red.\n",
        "    thickness: line thickness. Default value is 4.\n",
        "    display_str_list: a list of strings for each bounding box.\n",
        "                           \n",
        "  Raises:\n",
        "    ValueError: if boxes is not a [N, 4] array\n",
        "  \"\"\"\n",
        "  boxes_shape = boxes.shape\n",
        "  if not boxes_shape:\n",
        "    return\n",
        "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
        "    raise ValueError('Input must be of size [N, 4]')\n",
        "  \n",
        "  for i in range(boxes_shape[0]):\n",
        "    draw_ONE_bounding_box_on_image(image, \n",
        "                                   boxes[i, 1], boxes[i, 0], \n",
        "                                   boxes[i, 3], boxes[i, 2], \n",
        "                                   color[i], thickness, display_str_list[i])\n",
        "\n",
        "\n",
        "def draw_bounding_boxes_on_image_array(image:np.ndarray, boxes:np.ndarray, color:list=[], \n",
        "                                       thickness:int=1, display_str_list:tuple=()):\n",
        "  \"\"\"Draws bounding boxes on image (numpy array).\n",
        "\n",
        "  Args:\n",
        "    image: a numpy array object.\n",
        "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
        "           The coordinates are in normalized format between [0, 1].\n",
        "    color: color to draw bounding box. Default is red.\n",
        "    thickness: line thickness. Default value is 4.\n",
        "    display_str_list_list: a list of strings for each bounding box.\n",
        "  Raises:\n",
        "    ValueError: if boxes is not a [N, 4] array\n",
        "  \"\"\"\n",
        "  image_pil = PIL.Image.fromarray(image)\n",
        "  rgbimg = PIL.Image.new(\"RGBA\", image_pil.size)\n",
        "  rgbimg.paste(image_pil)\n",
        "  draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness, display_str_list)\n",
        "  return np.array(rgbimg)"
      ],
      "metadata": {
        "id": "mgoDp_sPvIwN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############### Matplotlib config\n",
        "plt.rc('image', cmap='gray')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "IhuDuRbavY9G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "def display_digits_with_boxes(digits, predictions, labels, pred_bboxes, bboxes, iou, title):\n",
        "  \"\"\"Utility to display a row of digits with their predictions.\n",
        "\n",
        "  Args:\n",
        "    digits : np.ndarray of shape (N,75,75,1)\n",
        "        Raw image with normalized pixel values (from 0 to 1)\n",
        "    predictions : np.ndarray of shape (N,)\n",
        "        Predicted label with the same shape as labels\n",
        "    labels : np.ndarray of shape (N,)\n",
        "        Labels of the digits (from 0 to 9)\n",
        "    pred_bboxes : np.ndarray of shape (n, N) ??\n",
        "        Predicted bboxes locations\n",
        "    bboxes : np.ndarray of shape (n, N)\n",
        "        Ground true bboxe locations\n",
        "    iou : list of shape (???)\n",
        "        IoU of each bboxes\n",
        "    title : str\n",
        "        Figure's title\n",
        "  \"\"\"\n",
        "  n = 10\n",
        "  indexes = np.random.choice(len(predictions), size=n)\n",
        "  n_digits = digits[indexes]\n",
        "  n_predictions = predictions[indexes]\n",
        "  n_labels = labels[indexes]\n",
        "\n",
        "  n_iou = []\n",
        "  if len(iou) > 0:\n",
        "    # If multiple bboxes\n",
        "    n_iou = iou[indexes]\n",
        "\n",
        "  if (len(pred_bboxes) > 0):\n",
        "    # If multiple bboxes predicted\n",
        "    n_pred_bboxes = pred_bboxes[indexes,:]\n",
        "\n",
        "  if (len(bboxes) > 0):\n",
        "    # If multiple ground truth bboxes\n",
        "    n_bboxes = bboxes[indexes,:]\n",
        "\n",
        "  # Rescale pixel values to un-normed values (from 0 -black- to 255 -white-)\n",
        "  n_digits = n_digits * 255.0\n",
        "  n_digits = n_digits.reshape(n, 75, 75)\n",
        "\n",
        "  # Set plot config\n",
        "  fig = plt.figure(figsize=(20, 4))\n",
        "  plt.title(title)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])\n",
        "  \n",
        "  for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i+1)\n",
        "    bboxes_to_plot = []\n",
        "    if (len(pred_bboxes) > i):\n",
        "      bboxes_to_plot.append(n_pred_bboxes[i])\n",
        "    \n",
        "    if (len(bboxes) > i):\n",
        "      bboxes_to_plot.append(n_bboxes[i])\n",
        "\n",
        "    img_to_draw = draw_bounding_boxes_on_image_array(image=n_digits[i], boxes=np.asarray(bboxes_to_plot), color=['red', 'green'], display_str_list=[\"true\", \"pred\"])\n",
        "    plt.xlabel(n_predictions[i])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    if n_predictions[i] != n_labels[i]:\n",
        "      ax.xaxis.label.set_color('red')\n",
        "    \n",
        "    plt.imshow(img_to_draw)\n",
        "\n",
        "    if len(iou) > i :\n",
        "      color = \"black\"\n",
        "      if (n_iou[i][0] < iou_threshold):\n",
        "        color = \"red\"\n",
        "      ax.text(0.2, -0.3, \"iou: %s\" %(n_iou[i][0]), color=color, transform=ax.transAxes)\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "  \"\"\"\n",
        "  Pull a batch from the datasets. This code is not very nice.\n",
        "  \n",
        "  Args:\n",
        "    training_dataset : torch.utils.data.Dataset\n",
        "        Dataset from the torch.utils.data.Dataset Pytorch class, returning the \n",
        "        training digits, labels and bboxes coordinates as batches such as : \n",
        "            - training digits : torch.Tensor of shape (batch_size, 1, 75, 75)\n",
        "            - labels : torch.Tensor of shape (batch_size, 10)\n",
        "            - bboxes coordinates : torch.Tensor of shape (batch_size, 4)\n",
        "    validation_dataset : torch.utils.data.Dataset \n",
        "        Dataset from the torch.utils.data.Dataset Pytorch class, returning the \n",
        "        whole validation digits, labels and bboxes coordinates.\n",
        "    N : int\n",
        "        Size of the training sample to extract from the training dataset\n",
        "\n",
        "  Returns:\n",
        "    N_train_ds_digits : np.ndarray of shape (N, 1, 75, 75)\n",
        "    N_train_ds_labels : np.ndarray of shape (N, 10)\n",
        "    N_train_ds_bboxes : np.ndarray of shape (N, 4)\n",
        "    validation_digits : np.ndarray of shape (len(validation_dataset), 1, 75, 75)\n",
        "    validation_labels : np.ndarray of shape (len(validation_dataset), 10)\n",
        "    validation_bboxes : np.ndarray of shape (len(validation_dataset), 4)\n",
        "  \"\"\"\n",
        "  ### get N training digits, labels and bboxes from one batch\n",
        "  ### turning the bboxes coordinates into ndarrays\n",
        "  one_batch_train_ds_digits, one_batch_train_ds_labels, one_batch_train_ds_bboxes = next(iter(training_dataset))\n",
        "  N_train_ds_digits = one_batch_train_ds_digits[:N].numpy()\n",
        "  N_train_ds_labels = one_batch_train_ds_labels[:N].numpy()\n",
        "  \n",
        "  N_train_ds_bboxes = one_batch_train_ds_bboxes[:N].numpy()\n",
        "  N_train_ds_bboxes_abs = N_train_ds_bboxes.copy()\n",
        "  \n",
        "  N_train_ds_bboxes_abs[:,0] = N_train_ds_bboxes[:,0] - (N_train_ds_bboxes[:,2]/2)\n",
        "  N_train_ds_bboxes_abs[:,1] = N_train_ds_bboxes[:,1] - (N_train_ds_bboxes[:,3]/2)\n",
        "  N_train_ds_bboxes_abs[:,2] = N_train_ds_bboxes[:,0] + (N_train_ds_bboxes[:,2]/2)\n",
        "  N_train_ds_bboxes_abs[:,3] = N_train_ds_bboxes[:,1] + (N_train_ds_bboxes[:,3]/2)\n",
        "  \n",
        "  ### get the whole validation digits, labels and bboxes\n",
        "  ### turning the bboxes coordinates into ndarrays\n",
        "  for validation_digits, validation_labels, validation_bboxes in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      validation_bboxes = validation_bboxes.numpy()\n",
        "      break\n",
        "\n",
        "  # turning one hot encoding labels into the corresponding digit\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  N_train_ds_labels = np.argmax(N_train_ds_labels, axis=1)\n",
        "\n",
        "  return (N_train_ds_digits, N_train_ds_labels, N_train_ds_bboxes_abs,\n",
        "          validation_digits, validation_labels, validation_bboxes)"
      ],
      "metadata": {
        "id": "mc_ExKjv7VZr"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Choosing device between CPU or GPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"\\n------------------------------------\")\n",
        "print(f\"Execute notebook on - {device} -\")\n",
        "print(\"------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOraK1TX7XZB",
        "outputId": "8eccc178-8f9c-46d4-8651-e0846221d0e3"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------\n",
            "Execute notebook on - cpu -\n",
            "------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numpy_pad_to_bounding_box(image, offset_height=0, offset_width=0, target_height=0, target_width=0):\n",
        "    assert image.shape[:-1][0] <= target_height-offset_height, \"height must be <= target - offset\"\n",
        "    assert image.shape[:-1][1] <= target_width-offset_width, \"width must be <= target - offset\"\n",
        "    \n",
        "    target_array = np.zeros((target_height, target_width, image.shape[-1]))\n",
        "\n",
        "    for k in range(image.shape[0]):\n",
        "        target_array[offset_height+k][offset_width:image.shape[1]+offset_width] = image[k]\n",
        "    \n",
        "    return target_array"
      ],
      "metadata": {
        "id": "TRspEjkE7aEK"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_mnist_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root:str, split:str=None, download:bool=False):\n",
        "        assert split, \"You have to specify the split.\"\n",
        "        \n",
        "        if split == \"train\":\n",
        "            train = True\n",
        "        elif split == \"test\":\n",
        "            train = False\n",
        "        \n",
        "        self.dataset = torchvision.datasets.MNIST(root=root, train=train, download=download)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def transform_pasting75(self, image, label):\n",
        "        ### xmin, ymin of digit\n",
        "        xmin = torch.randint(0, 48, (1,))\n",
        "        ymin = torch.randint(0, 48, (1,))\n",
        "        \n",
        "        image = torchvision.transforms.ToTensor()(image)\n",
        "        image = torch.reshape(image, (28,28,1,))\n",
        "        image = torch.from_numpy(numpy_pad_to_bounding_box(image, ymin, xmin, 75, 75))\n",
        "        image = image.permute(2, 0, 1) #(C,H,W)\n",
        "        image = image.to(torch.float)\n",
        "        \n",
        "        xmin, ymin = xmin.to(torch.float), ymin.to(torch.float)\n",
        "        # xmin, ymin, xmax, ymax of bbox\n",
        "        xmax_bbox = (xmin + 28)\n",
        "        ymax_bbox = (ymin + 28)\n",
        "        xmin_bbox = xmin\n",
        "        ymin_bbox = ymin\n",
        "\n",
        "        cx = (xmin+((xmax_bbox-xmin_bbox)/2)) / 75\n",
        "        cy = (ymin+((ymax_bbox-ymin_bbox)/2)) / 75\n",
        "        w = (xmax_bbox-xmin_bbox) / 75\n",
        "        h = (ymax_bbox-ymin_bbox) / 75\n",
        "\n",
        "\n",
        "        label_one_hot = F.one_hot(torch.as_tensor(label, dtype=torch.int64), 10)\n",
        "        bbox_coord = torch.Tensor([cx, cy, w, h])\n",
        "\n",
        "        return image, label_one_hot, bbox_coord\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        image, one_hot_label, bbox_coord = self.transform_pasting75(self.dataset[idx][0], self.dataset[idx][1])\n",
        "        \n",
        "        return (image, one_hot_label.to(torch.float), bbox_coord)\n"
      ],
      "metadata": {
        "id": "M7VztqFE71JZ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_dataset(BATCH_SIZE=64):\n",
        "    \"\"\"\n",
        "    Loads and maps the training split of the dataset using the custom dataset class. \n",
        "    \"\"\"\n",
        "    dataset = my_mnist_dataset(root=\"data\", split=\"train\", download=True)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    return dataloader, len(dataset)\n",
        "\n",
        "def get_validation_dataset(BATCH_SIZE = None):\n",
        "    \"\"\"\n",
        "    Loads and maps the validation split of the datasetusing the custom dataset class. \n",
        "    \"\"\"\n",
        "    dataset = my_mnist_dataset(root=\"data\", split=\"test\", download=True)\n",
        "    if BATCH_SIZE is None:\n",
        "        BATCH_SIZE = len(dataset)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    return dataloader, len(dataset)\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset, len_training_ds = get_training_dataset()\n",
        "validation_dataset, len_validation_ds = get_validation_dataset()"
      ],
      "metadata": {
        "id": "yQNznLfO8jOx"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_digits, training_labels, training_bboxes,\n",
        " validation_digits, validation_labels, validation_bboxes) = dataset_to_numpy_util(training_dataset, validation_dataset, 10)\n",
        "display_digits_with_boxes(training_digits, training_labels, training_labels, np.array([]), training_bboxes, np.array([]), \"training digits and their labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "UARQiNGd8rxL",
        "outputId": "9a7a69da-299b-4bbe-fbef-280cd7607a01"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 11 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lTKp-ZXAf3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}